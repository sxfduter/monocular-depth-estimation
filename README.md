# Mind Mapping for Depth Estimation
![结构图](https://github.com/sxfduter/monocular-depth-estimation/blob/master/%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE.PNG)
# monocular-depth-estimation
## VIO
* DeepVIO:  Self-supervised  Deep  Learning  of  Monocular  Visual  Inertial Odometry  using  3D  Geometric  Constraints
  + [paper](https://arxiv.org/pdf/1906.11435.pdf)
* DeepVO: A Deep Learning approach for Monocular Visual Odometry
  + [paper](https://arxiv.org/pdf/1611.06069.pdf)
## lidar 
* DeepLiDAR:Deep Surface Normal Guided Depth Prediction for Outdoor Scene from Sparse LiDAR Data and Single Color Image
  + [paper](https://arxiv.org/pdf/1812.00488.pdf)
* Pseudo-LiDAR++:Accurate Depth for 3D Object Detection in Autonomous Driving
  + [paper](https://arxiv.org/pdf/1906.06310.pdf)
* LiStereo: Generate Dense Depth Maps from LIDAR and Stereo Imagery
  + [paper](https://arxiv.org/pdf/1905.02744.pdf)
* Self-Supervised Sparse-to-Dense: Self-Supervised Depth Completion from LiDAR and Monocular Camera
  + [paper](https://arxiv.org/pdf/1807.00275.pdf)
* RGB and LiDAR fusion based 3D Semantic Segmentation for Autonomous Driving
  + [paper](https://arxiv.org/pdf/1906.00208.pdf)


## 2020
* Don’t Forget The Past: Recurrent Depth Estimation from Monocular Video
  + [paper](https://arxiv.org/pdf/2001.02613.pdf)
  + [code](https://github.com/wvangansbeke/Recurrent-Depth-Estimation)

## 2019
* 3D Packing for Self-Supervised Monocular Depth Estimation
  + [paper](https://arxiv.org/pdf/1905.02693.pdf)
  + [code](https://github.com/TRI-ML/packnet-sfm)
* Self-supervised Learning with Geometric Constraints in Monocular Video Connecting Flow, Depth, and Camera
  + [paper](https://arxiv.org/pdf/1907.05820.pdf)
* SuperDepth: Self-Supervised, Super-Resolved Monocular Depth Estimation
  + [paper](https://arxiv.org/pdf/1810.01849.pdf)
* HOW  MUCH POSITION INFORMATION DO CONVOLUTIONAL NEURAL NETWORKS ENCODE?
  + [paper](https://openreview.net/pdf?id=rJeB36NKvB)
* Instance-wise Depth and Motion Learning from Monocular Videos
  + [paper](https://arxiv.org/pdf/1912.09351.pdf)
  + [code](https://github.com/SeokjuLee/Insta-DM)
* How do neural networks see depth in single images?
  + [paper](https://arxiv.org/pdf/1905.07005.pdf)
* Unsupervised Scale-consistent Depth and Ego-motion Learning from Monocular Video
  + [paper](https://arxiv.org/pdf/1908.10553.pdf)
  + [code](https://github.com/JiawangBian/SC-SfMLearner-Release)
  + [project](https://jwbian.net/sc-sfmlearner)
* Towards Robust Monocular Depth Estimation:Mixing Datasets for Zero-Shot Cross-Dataset Transfer
  + [paper](https://arxiv.org/pdf/1907.01341.pdf)
* SGANVO: Unsupervised Deep Visual Odometry and Depth Estimation with Stacked Generative Adversarial Networks(***)
  + [paper](https://arxiv.org/abs/1906.08889)
* Pixel-Accurate Depth Evaluation in Realistic Driving Scenarios
  + [paper](https://arxiv.org/abs/1906.08953)
* Deep Robust Single Image Depth Estimation Neural Network Using Scene Understanding
  + [paper](https://arxiv.org/abs/1906.03279)
* Digging Into Self-Supervised Monocular Depth Estimation
  + [paper](https://arxiv.org/abs/1806.01260)
  + [code](https://github.com/nianticlabs/monodepth2)
  
  
* Unsupervised Monocular Depth and Ego-motion Learning with Structure and Semantics
  + [paper](https://arxiv.org/abs/1906.05717)
  + [code](https://sites.google.com/corp/view/struct2depth)
* Pseudo-LiDAR++: Accurate Depth for 3D Object Detection in Autonomous Driving
  + [paper](https://arxiv.org/abs/1906.06310)
  + [code](https://github.com/mileyan/Pseudo_Lidar_V2)
* Monocular Depth Estimation Using Relative Depth Maps
  + [paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Lee_Monocular_Depth_Estimation_Using_Relative_Depth_Maps_CVPR_2019_paper.pdf)
* Connecting the Dots: Learning Representations for Active Monocular Depth Estimation
  + [paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Riegler_Connecting_the_Dots_Learning_Representations_for_Active_Monocular_Depth_Estimation_CVPR_2019_paper.pdf)
  
* Soft Labels for Ordinal Regression
  + [paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Diaz_Soft_Labels_for_Ordinal_Regression_CVPR_2019_paper.pdf)

* A General and Adaptive Robust Loss Function
  + [paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Barron_A_General_and_Adaptive_Robust_Loss_Function_CVPR_2019_paper.pdf)

* Adversarial Structure Matching for Structured Prediction Tasks
  + [paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Hwang_Adversarial_Structure_Matching_for_Structured_Prediction_Tasks_CVPR_2019_paper.pdf)
* Veritatem Dies Aperit - Temporally Consistent Depth Prediction Enabled by a Multi-Task Geometric and Semantic Scene Understanding Approach
  + [paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Atapour-Abarghouei_Veritatem_Dies_Aperit_-_Temporally_Consistent_Depth_Prediction_Enabled_by_CVPR_2019_paper.pdf)
* Towards Scene Understanding: Unsupervised Monocular Depth Estimation With Semantic-Aware Representation
  + [paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Chen_Towards_Scene_Understanding_Unsupervised_Monocular_Depth_Estimation_With_Semantic-Aware_Representation_CVPR_2019_paper.pdf)
* Pattern-Affinitive Propagation across Depth, Surface Normal and Semantic Segmentation
  + [paper](https://arxiv.org/pdf/1906.03525v1.pdf)
* Generating and Exploiting Probabilistic Monocular Depth Estimates
  + [paper](https://arxiv.org/pdf/1906.05739v1.pdf)
* Attention-based Context Aggregation Network for Monocular Depth Estimation
  + [paper](https://arxiv.org/pdf/1901.10137v1.pdf)
  + [code](https://github.com/miraiaroha/ACAN)

* Monocular 3D Object Detection with Pseudo-LiDAR Point Cloud
  + [paper](https://arxiv.org/pdf/1903.09847v3.pdf)
  + [code](https://github.com/xinshuoweng/mono3D_PLiDAR)


* Geometry-Aware Symmetric Domain Adaptation for Monocular Depth Estimation
  + [paper](https://arxiv.org/pdf/1904.01870v1.pdf)
  + [code](https://github.com/sshan-zhao/GASDA)

* Learning monocular depth estimation infusing traditional stereo knowledge
  + [paper](https://arxiv.org/pdf/1904.04144v1.pdf)
  + [code](https://github.com/fabiotosi92/monoResMatch-Tensorflow)
  
* Learn Stereo, Infer Mono: Siamese Networks for Self-Supervised, Monocular, Depth Estimation
  + [paper](https://arxiv.org/pdf/1905.00401v1.pdf)
  + [code](https://github.com/mtngld/lsim)

* PackNet-SfM: 3D Packing for Self-Supervised Monocular Depth Estimation
  + [paper](https://arxiv.org/pdf/1905.02693v1.pdf)
  + [code](https://github.com/ToyotaResearchInstitute/packnet-sfm)
* Semi-Supervised Monocular Depth Estimation with Left-Right Consistency Using Deep Neural Network
  + [paper](https://arxiv.org/pdf/1905.07542v1.pdf)
  + [code](https://github.com/a-jahani/semiDepth)
* Sparsity Invariant CNNs
  + [paper](https://arxiv.org/pdf/1708.06500.pdf)
* SharpNet: Fast and Accurate Recovery of Occluding Contours in Monocular Depth Estimation
  + [paper](https://arxiv.org/pdf/1905.08598v1.pdf)
  + [code](https://github.com/MichaelRamamonjisoa/SharpNet)
* Learning the Depths of Moving People by Watching Frozen People
  + [paper](https://arxiv.org/abs/1904.11111)
  + [code](https://ai.googleblog.com/2019/05/moving-camera-moving-people-deep.html)
  
* Depth from Videos in the Wild: Unsupervised Monocular Depth Learning from Unknown Cameras
  + [paper](https://arxiv.org/abs/1904.04998v1)
* Real-time self-adaptive deep stereo
  + [paper](https://arxiv.org/pdf/1810.05424.pdf)
  + [code](https://github.com/CVLAB-Unibo/Real-time-self-adaptive-deep-stereo)
![结构图](https://raw.githubusercontent.com/CVLAB-Unibo/Learning2AdaptForStereo/master/architecture.png)
* Learning to Adapt for Stereo
  + [paper](https://arxiv.org/abs/1904.02957)
  + [code](https://github.com/CVLAB-Unibo/Learning2AdaptForStereo)
* Student Becoming the Master: Knowledge Amalgamation for Joint Scene Parsing, Depth Estimation, and More
  + [paper](https://arxiv.org/pdf/1904.10167.pdf)
* Learning the Depths of Moving People by Watching Frozen People
  + [paper](https://arxiv.org/pdf/1904.11111.pdf)
* Web Stereo Video Supervision for Depth Prediction from Dynamic Scenes
  + [paper](https://arxiv.org/pdf/1904.11112.pdf) 
  ![结构图](https://raw.githubusercontent.com/dwofk/fast-depth/master/img/visualization.png)
* FastDepth:  Fast  Monocular  Depth  Estimation  on  Embedded  Systems
  + [paper](https://arxiv.org/pdf/1903.03273.pdf)
  + [code](https://github.com/dwofk/fast-depth)
  + [webage](http://fastdepth.mit.edu/)
* AMNet:Deep Atrous Multiscale Stereo Disparity Estimation Networks
  + [paper](https://arxiv.org/abs/1904.09099)
* Depth from Videos in the Wild: Unsupervised Monocular Depth Learning from Unknown Cameras
  + [paper](https://arxiv.org/abs/1904.04998v1)
* Group-wise Correlation Stereo Network
  + [paper](https://arxiv.org/abs/1903.04025)
  + [code](https://github.com/xy-guo/GwcNet)
![结构图](https://github.com/sxfduter/monocular-depth-estimation/blob/master/Refine%20and%20Distill.png)
* Refine and Distill: Exploiting Cycle-Inconsistency and Knowledge Distillation for Unsupervised Monocular Depth Estimation
  + [paper](https://arxiv.org/abs/1903.04202)
  
![结构图](https://github.com/sxfduter/monocular-depth-estimation/blob/master/Two-branch%20%20decoder.png)
* Bilateral Cyclic Constraint and Adaptive Regularization for Unsupervised Monocular Depth Prediction
  + [paper](https://arxiv.org/abs/1903.07309)
![结构图](https://github.com/sxfduter/monocular-depth-estimation/blob/master/DKN.png)
* Deformable kernel networks for guided depth map upsampling
  + [paper](https://arxiv.org/abs/1903.11286?context=cs.CV)
  + [code](https://cvlab-yonsei.github.io/projects/DKN)
![结构图](https://github.com/sxfduter/monocular-depth-estimation/blob/master/multitask%20refinenet.PNG "multitask%20refinenet")
* Real-Time Joint Semantic Segmentation and Depth Estimation Using Asymmetric Annotations
  + [paper](https://arxiv.org/pdf/1809.04766.pdf)
  + [code](https://github.com/drsleep/multi-task-refinenet)
![结构图](https://github.com/sxfduter/monocular-depth-estimation/blob/master/Competitive%20Collaboration.PNG "Competitive%20Collaboration")
* Competitive Collaboration: Joint Unsupervised Learning of Depth, Camera
Motion, Optical Flow and Motion Segmentation
  + [paper](https://arxiv.org/pdf/1805.09806.pdf)
  + [code](https://github.com/anuragranj/cc)
  
* Privacy Protection in Street-View Panoramas using Depth and Multi-View Imagery
  + [paper](https://arxiv.org/abs/1903.11532)
* DFineNet: Ego-Motion Estimation and Depth Refinement from Sparse, Noisy Depth Input with RGB Guidance
  + [paper](https://arxiv.org/abs/1903.06397)
* Bilateral Cyclic Constraint and Adaptive Regularization for Unsupervised Monocular Depth Prediction
  + [paper](https://arxiv.org/abs/1903.07309)
* Anytime Stereo Image Depth Estimation on Mobile Devices(**)
  + [paper](https://arxiv.org/abs/1810.11408)
  + [code](https://github.com/mileyan/AnyNet)
* Refine and Distill: Exploiting Cycle-Inconsistency and Knowledge Distillation for Unsupervised Monocular Depth Estimation(CVPR2019)
  + [paper](https://arxiv.org/abs/1903.04202)
* Self-supervised Learning for Single View Depth and Surface Normal Estimation
  + [paper](https://arxiv.org/abs/1903.00112)
* DeepLiDAR: Deep Surface Normal Guided Depth Prediction for Outdoor Scene from Sparse LiDAR Data and Single Color Image
  + [paper](https://arxiv.org/abs/1812.00488v1)
* A Motion Free Approach to Dense Depth Estimation in Complex Dynamic Scene
  + [paper](https://arxiv.org/abs/1902.03791)
* Self-supervised Learning for Dense Depth Estimation in Monocular Endoscopy
  + [paper](https://arxiv.org/abs/1902.07766?context=cs)
* Region Deformer Networks for Unsupervised Depth Estimation from Unconstrained Monocular Videos
  + [paper](https://arxiv.org/abs/1902.09907)
* Single Image Deblurring and Camera Motion Estimation with Depth Map
  + [paper](https://arxiv.org/abs/1903.00231)
* SweepNet: Wide-baseline Omnidirectional Depth Estimation
  + [paper](https://arxiv.org/abs/1902.10904)
* Recurrent MVSNet for High-resolution Multi-view Stereo Depth Inference
  + [paper](https://arxiv.org/abs/1902.10556)
* Multi-layer Depth and Epipolar Feature Transformers for 3D Scene Reconstruction
  + [paper](https://arxiv.org/abs/1902.06729)
* Depth-Map Generation using Pixel Matching in Stereoscopic Pair of Images
  + [paper](https://arxiv.org/abs/1902.03471)
* Unstructured Multi-View Depth Estimation Using Mask-Based Multiplane Representation
  + [paper](https://arxiv.org/abs/1902.02166)
* DFuseNet: Deep Fusion of RGB and Sparse Depth Information for Image Guided Dense Depth Completion
  + [paper](https://arxiv.org/abs/1902.00761)
* Attention-based Context Aggregation Network for Monocular Depth Estimation
  + [paper](https://arxiv.org/abs/1901.10137)
  ![结构图](https://github.com/sxfduter/monocular-depth-estimation/blob/master/Depth%20Prediction%20Without%20the%20Sensors.PNG "Depth Prediction Without the Sensors")
* Depth Prediction Without the Sensors: Leveraging Structure for Unsupervised Learning from Monocular Videos(已复现)
  + [paper](https://arxiv.org/pdf/1811.06152.pdf)
  + [code](https://github.com/tensorflow/models/tree/master/research/struct2depth)
  + [webpage](https://sites.google.com/view/struct2depth)
  
   
  
   
## 2018
* Robust Depth Estimation from Auto Bracketed Images
  + [paper](https://arxiv.org/pdf/1803.07702.pdf)

* PWC-Net: CNNs for Optical Flow Using Pyramid, Warping, and Cost Volume
  + [paper](https://arxiv.org/pdf/1709.02371.pdf)
  + [code](https://github.com/NVlabs/PWC-Net)

![结构图](https://github.com/lawy623/SVS/raw/master/figs/result.png)
* Single View Stereo Matching
  + [paper](https://arxiv.org/abs/1803.02612)
  + [code](https://github.com/lawy623/SVS)

* Geometry meets semantics for semi-supervised monocular depth estimation
  + [paper](https://arxiv.org/pdf/1810.04093v2.pdf)
  + [code](https://github.com/CVLAB-Unibo/Semantic-Mono-Depth)
* Learning Monocular Depth by Distilling Cross-domain Stereo Networks
  + [paper](https://arxiv.org/pdf/1808.06586v1.pdf)
  + [code](https://github.com/xy-guo/Learning-Monocular-Depth-by-Stereo)
* Revisiting Single Image Depth Estimation: Toward Higher Resolution Maps with Accurate Object Boundaries
  + [paper](https://arxiv.org/pdf/1803.08673v2.pdf)
  + [code](https://github.com/JunjH/Revisiting_Single_Depth_Estimation)
* Deep Ordinal Regression Network for Monocular Depth Estimation
  + [paper](https://arxiv.org/pdf/1806.02446v1.pdf)
  + [code](https://github.com/hufu6371/DORN)
* High Quality Monocular Depth Estimation via Transfer Learning
  + [paper](https://arxiv.org/pdf/1812.11941v2.pdf)
  + [code](https://github.com/ialhashim/DenseDepth)
* Digging Into Self-Supervised Monocular Depth Estimation
  + [paper](https://arxiv.org/pdf/1806.01260v3.pdf)
  + [code](https://github.com/nianticlabs/monodepth2)
  + [video](https://www.youtube.com/watch?v=sIN1Tp3wIbQ)
* On the Importance of Stereo for Accurate Depth Estimation: An Efficient Semi-Supervised Deep Neural Network Approach
  + [paper](https://arxiv.org/pdf/1803.09719v3.pdf)
  + [code](https://github.com/NVIDIA-AI-IOT/redtail)

<div align=center><img width="200" height="150" src="https://camo.githubusercontent.com/bfeda04ca5dc388a4977c3584ca5b82386bc6f91/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f7669643264657074682f6d656469612f73616d706c655f766964656f5f736d616c6c2e676966"/></div>
<div align=center><img width="400" height="500" src="https://camo.githubusercontent.com/878c3b95ff7066d1294c3b2c72a246d035f85db7/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f7669643264657074682f6d656469612f617070726f6163682e706e67"/></div>

* Unsupervised Learning of Depth and Ego-Motion from Monocular Video Using 3D Geometric Constraints
  + [paper](https://arxiv.org/pdf/1802.05522.pdf)
  + [code](https://github.com/tensorflow/models/tree/master/research/vid2depth)
  + [Project website](https://sites.google.com/view/vid2depth)
![结构图](https://github.com/sxfduter/monocular-depth-estimation/blob/master/Depth%20VO%20Feat.PNG "Depth-VO-Feat")
* Unsupervised Learning of Monocular Depth Estimation and Visual Odometry with Deep Feature Reconstruction
  + [paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Zhan_Unsupervised_Learning_of_CVPR_2018_paper.pdf)
  + [code](https://github.com/Huangying-Zhan/Depth-VO-Feat)
![结构图](https://github.com/sxfduter/monocular-depth-estimation/blob/master/UnDepthflow.PNG "UnDepthflow")
* Joint Unsupervised Learning of Optical Flow and Depth by Watching Stereo Videos
  + [paper](https://arxiv.org/pdf/1810.03654.pdf)
  + [code](https://github.com/baidu-research/UnDepthflow)
* DF-Net: Unsupervised Joint Learning of Depth and Flow using Cross-Task Consistency
  + [paper](https://arxiv.org/pdf/1809.01649.pdf)
  + [code](https://github.com/vt-vl-lab/DF-Net)
  + [webpage](http://yuliang.vision/DF-Net/)
  
 ![结构图]( https://github.com/yzcjtr/GeoNet/raw/master/misc/overview.jpg)
 * GeoNet: Unsupervised Learning of Dense Depth, Optical Flow and Camera Pose (CVPR 2018)
   + [paper](https://arxiv.org/abs/1803.02276)
   + [code]( https://github.com/yzcjtr/GeoNet)
 * GeoNet:Geometric Neural Network for Joint Depth and Surface Normal Estimation
   + [paper]()
* Driving Scene Perception Network: Real-time Joint Detection, Depth Estimation and Semantic Segmentation
  + [paper]( https://arxiv.org/pdf/1803.03778.pdf)
* Epipolar Geometry based Learning of Multi-view Depth and Ego-Motion from Monocular Sequences
  + [paper](https://arxiv.org/abs/1812.11922)
* SfMLearner++: Learning Monocular Depth & Ego-Motion using Meaningful Geometric Constraints
  + [paper](https://arxiv.org/abs/1812.08370)
* Unsupervised Event-based Learning of Optical Flow, Depth, and Egomotion
  + [paper](https://arxiv.org/abs/1812.08156)
* Fast and Accurate Depth Estimation from Sparse Light Fields
  + [paper](https://arxiv.org/abs/1812.06856)
* Geometry meets semantics for semi-supervised monocular depth estimation
  + [paper](https://arxiv.org/abs/1810.04093)
* Joint Unsupervised Learning of Optical Flow and Depth by Watching Stereo Videos
  + [paper](https://arxiv.org/abs/1810.03654)
* Learning Depth with Convolutional Spatial Propagation Network
  + [paper](https://arxiv.org/abs/1810.02695)
* SuperDepth: Self-Supervised, Super-Resolved Monocular Depth Estimation
  + [paper](https://arxiv.org/abs/1810.01849)
* CNN-SVO: Improving the Mapping in Semi-Direct Visual Odometry Using Single-Image Depth Prediction
  + [paper](https://arxiv.org/abs/1810.01011)
* Unsupervised Learning of Dense Optical Flow, Depth and Egomotion from Sparse Event Data
  + [paper](https://arxiv.org/abs/1809.08625)
* GANVO: Unsupervised Deep Monocular Visual Odometry and Depth Estimation with Generative Adversarial Networks
  + [paper](https://arxiv.org/abs/1809.05786)
* Real-Time Joint Semantic Segmentation and Depth Estimation Using Asymmetric Annotations
  + [paper](https://arxiv.org/abs/1809.04766)
* DF-Net: Unsupervised Joint Learning of Depth and Flow using Cross-Task Consistency
  + [paper](https://arxiv.org/abs/1809.01649)
* Sparse-to-Continuous: Enhancing Monocular Depth Estimation using Occupancy Maps
  + [paper](https://arxiv.org/abs/1809.09061)
* Deep Depth from Defocus: how can defocus blur improve 3D estimation using dense neural networks?
  + [paper](https://arxiv.org/abs/1809.01567)
* A Deeper Insight into the UnDEMoN: Unsupervised Deep Network for Depth and Ego-Motion Estimation
  + [paper](https://arxiv.org/abs/1809.00969)
* Detail Preserving Depth Estimation from a Single Image Using Attention Guided Networks
  + [paper](https://arxiv.org/abs/1809.00646)
* Rethinking Monocular Depth Estimation with Adversarial Training
  + [paper](https://arxiv.org/abs/1808.07528)
* Deeply Supervised Depth Map Super-Resolution as Novel View Synthesis
  + [paper](https://arxiv.org/abs/1808.08688)
* LEGO: Learning Edge with Geometry all at Once by Watching Videos
  + [paper](https://arxiv.org/abs/1803.05648)
  + [code](https://github.com/zhenheny/LEGO)
* Learning monocular visual odometry with dense 3D mapping from dense 3D flow
  + [paper](https://arxiv.org/pdf/1803.02286.pdf)
  
![结构图](https://github.com/MightyChaos/MightyChaos.github.io/raw/master/projects/cvpr18_chaoyang/demo.gif)
![结构图](https://github.com/sxfduter/monocular-depth-estimation/blob/master/LKVOLearner.PNG)

* Learning Depth from Monocular Videos using Direct Methods
  + [paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_Learning_Depth_From_CVPR_2018_paper.pdf)
  + [code](https://github.com/MightyChaos/LKVOLearner)
  
## 2017
* Semi-Supervised Deep Learning for Monocular Depth Map Prediction
  + [paper](https://arxiv.org/pdf/1702.02706.pdf)
* Unsupervised Monocular Depth Estimation with Left-Right Consistency  
  + [paper](https://arxiv.org/pdf/1609.03677v3.pdf)  
  + [code tensorflow](https://github.com/mrharicot/monodepth)  
  + [code pytorch](https://github.com/alwynmathew/monodepth-pytorch)
* A Two-Streamed Network for Estimating Fine-Scaled Depth Maps from Single RGB Images
  + [paper](https://arxiv.org/abs/1607.00730)
* Single-Image Depth Perception in the Wild
  + [paper](https://arxiv.org/abs/1604.03901)
*  Unsupervised Learning of Depth and Ego-Motion from Monocular Video Using 3D Geometric Constraints
   + [paper](https://arxiv.org/pdf/1802.05522v1.pdf)  
   
 ![结构图]( https://github.com/sxfduter/monocular-depth-estimation/blob/master/SfMLearner1.PNG "SfMLearner1") 
* Unsupervised Learning of Depth and Ego-Motion from Video(已复现)
  + [paper](https://people.eecs.berkeley.edu/~tinghuiz/projects/SfMLearner/cvpr17_sfm_final.pdf)
  + [code](https://github.com/tinghuiz/SfMLearner)
  + [project webpage](https://people.eecs.berkeley.edu/~tinghuiz/projects/SfMLearner/)
## 2016



* Fast Robust Monocular Depth Estimation for Obstacle Detection with Fully Convolutional Networks
  + [paper](https://arxiv.org/pdf/1607.06349v1.pdf)
* Parse Geometry from a Line: Monocular Depth Estimation with Partial Laser Observation
  + [paper](https://arxiv.org/pdf/1611.02174v1.pdf)
* Joint Semantic Segmentation and Depth Estimation with Deep Convolutional Networks
  + [paper](https://arxiv.org/abs/1604.07480v1)
* Deeper Depth Prediction with Fully Convolutional Residual Networks
  + [paper](https://arxiv.org/abs/1606.00373)
* Deep3D Fully Automatic 2D-to-3D Video Conversion with Deep Convolutional Neural Networks
  + [paper](https://arxiv.org/abs/1604.03650v1)
## 2015
* Predicting Depth, Surface Normals and Semantic Labels with a Common Multi-Scale Convolutional Architecture
  + [paper](https://arxiv.org/abs/1411.4734)
## 2014
* Deep Convolutional Neural Fields for Depth Estimation from a Single Image 
  + [paper](https://arxiv.org/abs/1411.6387)
* Depth Map Prediction from a Single Image using a Multi-Scale Deep Network
  + [paper](https://arxiv.org/abs/1406.2283v1)
  + [code for pytorch](https://github.com/DhruvJawalkar/Depth-Map-Prediction-from-a-Single-Image-using-a-Multi-Scale-Deep-Network)
  
# GAN for depth estimation
These use the Generator to generate the depth map instead of using estimation networks. From these work, it can be seen that the generative nature in GAN networks is beneficial to the scenes with dynamic objects. However, these visual odometry related GANs focus on the depth estimation, but not on the ego-motion estimation.
* Generative Adversarial Networks for unsupervised monocular depth prediction
  + [paper](http://vision.deis.unibo.it/~ftosi/papers/monoGan.pdf)
* Unsupervised 
